{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed63f11",
   "metadata": {},
   "source": [
    "# Data Modeling\n",
    "## Code Sources\n",
    "### Ken Jee - Data Project from Scratch video series\n",
    "    [Video Link] (https://www.youtube.com/watch?v=7O4dpR9QMIM)\n",
    "    [GitHub Repo Link] (https://github.com/PlayingNumbers/ds_salary_proj)\n",
    "    \n",
    "### GreekDataGuy\n",
    "    https://towardsdatascience.com/productionize-a-machine-learning-model-with-flask-and-heroku-8201260503d2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd036fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "\n",
    "\n",
    "df = pd.read_csv('cleantrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57e4368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose relevant columns\n",
    "df_model = df[['LotArea', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'Foundation', 'TotalFinSF', \n",
    "               'TotalBath', 'BedroomAbvGr', 'GarageCars', 'YrSold', 'SalePrice']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8762992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummy data\n",
    "df_dum = pd.get_dummies(df_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f68df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_dum.drop('SalePrice', axis = 1)\n",
    "y = df_dum.SalePrice.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f32b5a8",
   "metadata": {},
   "source": [
    "## Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3cf01e",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "379b8d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.640</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.627</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   46.95</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 09 Apr 2023</td> <th>  Prob (F-statistic):</th> <td>4.75e-68</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:36:58</td>     <th>  Log-Likelihood:    </th> <td> -4377.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   357</td>      <th>  AIC:               </th> <td>   8784.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   343</td>      <th>  BIC:               </th> <td>   8838.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>             <td>-1.581e+06</td> <td> 3.57e+06</td> <td>   -0.444</td> <td> 0.658</td> <td>-8.59e+06</td> <td> 5.43e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LotArea</th>           <td>    0.6362</td> <td>    0.548</td> <td>    1.161</td> <td> 0.246</td> <td>   -0.441</td> <td>    1.714</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OverallCond</th>       <td> 7999.5081</td> <td> 4504.161</td> <td>    1.776</td> <td> 0.077</td> <td> -859.746</td> <td> 1.69e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>YearBuilt</th>         <td>    2.2664</td> <td>  346.367</td> <td>    0.007</td> <td> 0.995</td> <td> -679.004</td> <td>  683.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>YearRemodAdd</th>      <td>  835.6317</td> <td>  417.578</td> <td>    2.001</td> <td> 0.046</td> <td>   14.296</td> <td> 1656.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TotalFinSF</th>        <td>   22.4197</td> <td>    5.240</td> <td>    4.278</td> <td> 0.000</td> <td>   12.112</td> <td>   32.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TotalBath</th>         <td>  1.36e+04</td> <td> 6221.223</td> <td>    2.185</td> <td> 0.030</td> <td> 1359.337</td> <td> 2.58e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BedroomAbvGr</th>      <td> 2.016e+04</td> <td> 5104.917</td> <td>    3.948</td> <td> 0.000</td> <td> 1.01e+04</td> <td> 3.02e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GarageCars</th>        <td> 6.864e+04</td> <td> 6983.090</td> <td>    9.830</td> <td> 0.000</td> <td> 5.49e+04</td> <td> 8.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>YrSold</th>            <td>   51.2536</td> <td> 2118.461</td> <td>    0.024</td> <td> 0.981</td> <td>-4115.557</td> <td> 4218.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Foundation_BrkTil</th> <td>-3.099e+05</td> <td> 7.13e+05</td> <td>   -0.434</td> <td> 0.664</td> <td>-1.71e+06</td> <td> 1.09e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Foundation_CBlock</th> <td>-3.294e+05</td> <td> 7.15e+05</td> <td>   -0.461</td> <td> 0.645</td> <td>-1.74e+06</td> <td> 1.08e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Foundation_PConc</th>  <td>-3.188e+05</td> <td> 7.16e+05</td> <td>   -0.445</td> <td> 0.656</td> <td>-1.73e+06</td> <td> 1.09e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Foundation_Slab</th>   <td>-3.007e+05</td> <td> 7.11e+05</td> <td>   -0.423</td> <td> 0.673</td> <td> -1.7e+06</td> <td>  1.1e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Foundation_Wood</th>   <td>-3.225e+05</td> <td> 7.13e+05</td> <td>   -0.452</td> <td> 0.652</td> <td>-1.73e+06</td> <td> 1.08e+06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>128.011</td> <th>  Durbin-Watson:     </th> <td>   1.870</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2795.381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.933</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.581</td>  <th>  Cond. No.          </th> <td>2.79e+19</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 7.8e-29. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.640\n",
       "Model:                            OLS   Adj. R-squared:                  0.627\n",
       "Method:                 Least Squares   F-statistic:                     46.95\n",
       "Date:                Sun, 09 Apr 2023   Prob (F-statistic):           4.75e-68\n",
       "Time:                        20:36:58   Log-Likelihood:                -4377.8\n",
       "No. Observations:                 357   AIC:                             8784.\n",
       "Df Residuals:                     343   BIC:                             8838.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "const             -1.581e+06   3.57e+06     -0.444      0.658   -8.59e+06    5.43e+06\n",
       "LotArea               0.6362      0.548      1.161      0.246      -0.441       1.714\n",
       "OverallCond        7999.5081   4504.161      1.776      0.077    -859.746    1.69e+04\n",
       "YearBuilt             2.2664    346.367      0.007      0.995    -679.004     683.537\n",
       "YearRemodAdd        835.6317    417.578      2.001      0.046      14.296    1656.968\n",
       "TotalFinSF           22.4197      5.240      4.278      0.000      12.112      32.727\n",
       "TotalBath           1.36e+04   6221.223      2.185      0.030    1359.337    2.58e+04\n",
       "BedroomAbvGr       2.016e+04   5104.917      3.948      0.000    1.01e+04    3.02e+04\n",
       "GarageCars         6.864e+04   6983.090      9.830      0.000    5.49e+04    8.24e+04\n",
       "YrSold               51.2536   2118.461      0.024      0.981   -4115.557    4218.064\n",
       "Foundation_BrkTil -3.099e+05   7.13e+05     -0.434      0.664   -1.71e+06    1.09e+06\n",
       "Foundation_CBlock -3.294e+05   7.15e+05     -0.461      0.645   -1.74e+06    1.08e+06\n",
       "Foundation_PConc  -3.188e+05   7.16e+05     -0.445      0.656   -1.73e+06    1.09e+06\n",
       "Foundation_Slab   -3.007e+05   7.11e+05     -0.423      0.673    -1.7e+06     1.1e+06\n",
       "Foundation_Wood   -3.225e+05   7.13e+05     -0.452      0.652   -1.73e+06    1.08e+06\n",
       "==============================================================================\n",
       "Omnibus:                      128.011   Durbin-Watson:                   1.870\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2795.381\n",
       "Skew:                           0.933   Prob(JB):                         0.00\n",
       "Kurtosis:                      16.581   Cond. No.                     2.79e+19\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 7.8e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statsmodels regression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X_sm = X = sm.add_constant(X)\n",
    "model = sm.OLS(y,X_sm)\n",
    "model.fit().summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "98faabca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-32982.85048422652"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn linear model\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "np.mean(cross_val_score(lm,X_train,y_train, scoring = 'neg_mean_absolute_error', cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea63198",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "75a70c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.394e+10, tolerance: 1.884e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-33009.875909432936"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_l = Lasso(alpha=.099)\n",
    "lm_l.fit(X_train,y_train)\n",
    "np.mean(cross_val_score(lm_l,X_train,y_train, scoring = 'neg_mean_absolute_error', cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "511feb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e+10, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.327e+11, tolerance: 1.314e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.011, 0.012, 0.013, 0.014, 0.015, 0.016, 0.017, 0.018, 0.019, 0.02, 0.021, 0.022, 0.023, 0.024, 0.025, 0.026, 0.027, 0.028, 0.029, 0.03, 0.031, 0.032, 0.033, 0.034, 0.035, 0.036, 0.037, 0.038, 0.039, 0.04, 0.041, 0.042, 0.043, 0.044, 0.045, 0.046, 0.047, 0.048, 0.049, 0.05, 0.051, 0.052, 0.053, 0.054, 0.055, 0.056, 0.057, 0.058, 0.059, 0.06, 0.061, 0.062, 0.063, 0.064, 0.065, 0.066, 0.067, 0.068, 0.069, 0.07, 0.071, 0.072, 0.073, 0.074, 0.075, 0.076, 0.077, 0.078, 0.079, 0.08, 0.081, 0.082, 0.083, 0.084, 0.085, 0.086, 0.087, 0.088, 0.089, 0.09, 0.091, 0.092, 0.093, 0.094, 0.095, 0.096, 0.097, 0.098, 0.099]\n",
      "[-33010.926172664884, -33010.88882758171, -33010.85148249979, -33010.81413741547, -33010.7767923322, -33010.73944724825, -33010.70210216763, -33010.664757082945, -33010.62741200234, -33010.59006691646, -33010.552721835906, -33010.51537674903, -33010.47803166847, -33010.44068658779, -33010.40334149915, -33010.36599641858, -33010.32865133785, -33010.29130625734, -33010.25396116666, -33010.2166160861, -33010.17927100541, -33010.14192592491, -33010.10458083171, -33010.067235751136, -33010.029890670485, -33010.01223079628, -33010.01036964453, -33010.00850187493, -33010.00663453935, -33010.004767160644, -33010.00289987047, -33010.0010320932, -33009.99916462601, -33009.99729684505, -33009.995429602845, -33009.99356220457, -33009.99169475934, -33009.98982731421, -33009.98795903567, -33009.98609180419, -33009.98422473526, -33009.98235700247, -33009.98048955718, -33009.97862145449, -33009.976754775205, -33009.97488651218, -33009.9730197964, -33009.97115149012, -33009.96928486177, -33009.96741666408, -33009.96554910819, -33009.9636822608, -33009.9618138045, -33009.95994737055, -33009.958079327655, -33009.95621209534, -33009.95434453955, -33009.95247662948, -33009.95060967137, -33009.948741014385, -33009.94687482541, -33009.94500693753, -33009.94313871553, -33009.94127164871, -33009.93940429223, -33009.93753666985, -33009.93566877568, -33009.933802133746, -33009.93193372749, -33009.93006658542, -33009.928199250884, -33009.926331695075, -33009.92446391796, -33009.92259587345, -33009.920729359605, -33009.91886090348, -33009.9169940045, -33009.91512689133, -33009.91325960111, -33009.91139213395, -33009.90952448958, -33009.907656668125, -33009.90578866959, -33009.903920398414, -33009.9020540228, -33009.90018542836, -33009.89831870833, -33009.89645181648, -33009.894584791975, -33009.89271559682, -33009.89084832026, -33009.888980884854, -33009.88711329805, -33009.885245552665, -33009.88337765087, -33009.881511901236, -33009.87964381407, -33009.8777755606, -33009.875909432936]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+10, tolerance: 1.306e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Determine best alpha\n",
    "\n",
    "alpha = []\n",
    "error = []\n",
    "\n",
    "for i in range(1,100):\n",
    "    alpha.append(i/1000)\n",
    "    lml = Lasso(alpha=(i/1000))\n",
    "    error.append(np.mean(cross_val_score(lml,X_train,y_train, scoring = 'neg_mean_absolute_error', cv=3)))\n",
    "    \n",
    "print(alpha)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d042d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20110049220>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(alpha,error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b2d3f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.099</td>\n",
       "      <td>-33009.875909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha         error\n",
       "98  0.099 -33009.875909"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err = tuple(zip(alpha,error))\n",
    "df_err = pd.DataFrame(err, columns = ['alpha', 'error'])\n",
    "df_err[df_err.error == max(df_err.error)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3cc42b",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1315ad1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-23540.580210526314"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Regressor model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "np.mean(cross_val_score(rf,X_train,y_train, scoring = 'neg_mean_absolute_error', cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f09ace6",
   "metadata": {},
   "source": [
    "## Tune Models Using GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d50cd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'n_estimators':range(10,300,10), 'max_features':('auto', 'sqrt', 'log2'), }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f3e91ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(rf,parameters, scoring='neg_mean_absolute_error', cv=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72e7ec82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestRegressor(),\n",
       "             param_grid={&#x27;max_features&#x27;: (&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;),\n",
       "                         &#x27;n_estimators&#x27;: range(10, 300, 10)},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RandomForestRegressor(),\n",
       "             param_grid={&#x27;max_features&#x27;: (&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;),\n",
       "                         &#x27;n_estimators&#x27;: range(10, 300, 10)},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(),\n",
       "             param_grid={'max_features': ('auto', 'sqrt', 'log2'),\n",
       "                         'n_estimators': range(10, 300, 10)},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cc7112b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-22577.571517027867"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3ee127dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_features=&#x27;log2&#x27;, n_estimators=170)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_features=&#x27;log2&#x27;, n_estimators=170)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_features='log2', n_estimators=170)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "96c2a843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test ensembles\n",
    "tpred_lm = lm.predict(X_test)\n",
    "tpred_lml = lm_l.predict(X_test)\n",
    "tpred_rf =gs.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7ea73461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40137.496433003136"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test,tpred_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f1d1ff58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40137.34370099346"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,tpred_lml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "01b5a1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29087.05947712418"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,tpred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "12c91fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33949.823492042095"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,(tpred_lm+tpred_rf)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a761870",
   "metadata": {},
   "source": [
    "# Results\n",
    "Basic results for our regression models to predict Sale Price on \n",
    "the Ames data.\n",
    "| Model | Set | MAE |\n",
    "|:---|:---|:---|\n",
    "|Linear Regression|Training|32983|\n",
    "|Linear Regression|Test|40137|\n",
    "|Lasso Regression|Training|33010|\n",
    "|Lasso Regression|Test|40137|\n",
    "|Random Forest Regression|Training|23541|\n",
    "|Random Forest Regression|Test|29087|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0e6b78",
   "metadata": {},
   "source": [
    "## Create API\n",
    "As I was creating the API I ran into too many issues and ran out of time, so I just set up functions to input the data.  In the future I would like to create a functioning API for this project.\n",
    "\n",
    "### Sources\n",
    "    Ken Jee: Creating a Data Science Project from Scratch (Part 6)\n",
    "    https://www.youtube.com/watch?v=nUOh_lDMHOU\n",
    "    github repo for this project: https://github.com/PlayingNumbers/ds_...\n",
    "    \n",
    "    Article By Chris that we Followed to Create the API: https://towardsdatascience.com/produc...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "416b393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickl = {'model': gs.best_estimator_}\n",
    "pickle.dump(pickl, open( 'model_file' + \".p\", \"wb\" ) )\n",
    "\n",
    "file_name = \"model_file.p\"\n",
    "with open(file_name, 'rb') as pickled:\n",
    "    data = pickle.load(pickled)\n",
    "    model = data['model']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a4983d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([217214.47058824])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test.iloc[1,:].values.reshape(1,-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8ecf692b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12435.0,\n",
       " 5.0,\n",
       " 2001.0,\n",
       " 2001.0,\n",
       " 2153.0,\n",
       " 2.5,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 2008.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_test.iloc[1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b447d4",
   "metadata": {},
   "source": [
    "## Predict the sale price of the study house\n",
    "Features to input:\n",
    "Lot Area: 23958, Overall Cond:8, Year Built:1962, Year Remodeled: 2005, Total Finished Sqft: 2322, Bathrooms: 1.5, Bedrooms: 4, GarageCars: 2, Year Sold: 2011, Foundation: Poured Concrete\n",
    "\n",
    "Result: 208,490"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8ef27bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('{\"response\": 208489.61764705883}', 200)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import flask\n",
    "from flask import Flask, jsonify, request\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def load_models():\n",
    "    file_name = \"FlaskAPI/models/model_file.p\"\n",
    "    with open(file_name, 'rb') as pickled:\n",
    "        data = pickle.load(pickled)\n",
    "        model = data['model']\n",
    "    return model\n",
    "\n",
    "def predict():    # input study house features\n",
    "    # features = [['LotArea', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'TotalFinSF', 'TotalBath', 'BedroomAbvGr', 'GarageCars', 'YrSold','Foundation']]\n",
    "    x = np.array([[23958, 8, 1962, 2005, 2322, 1.5, 4, 2, 2011, 0, 0,1,0,0]])\n",
    "    #x = np.array(data_in),reshape(1,-1)    # load model\n",
    "    model = load_models()\n",
    "    prediction = model.predict(x)[0]    \n",
    "    response = json.dumps({'response': prediction})\n",
    "    return response, 200\n",
    "\n",
    "predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0aebd2",
   "metadata": {},
   "source": [
    "## Predict the sale price of the study house with updates\n",
    "Features to input: Lot Area: 23958, Overall Cond:8, Year Built:1962, Year Remodeled: 2011, Total Finished Sqft: 2822, Bathrooms: 2.5, Bedrooms: 5, GarageCars: 2, Year Sold: 2011, Foundation: Poured Concrete\n",
    "\n",
    "Result: 266,028"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91b93e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amber\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('{\"response\": 266027.64705882355}', 200)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_models():\n",
    "    file_name = \"FlaskAPI/models/model_file.p\"\n",
    "    with open(file_name, 'rb') as pickled:\n",
    "        data = pickle.load(pickled)\n",
    "        model = data['model']\n",
    "    return model\n",
    "\n",
    "def predict():    # input study house with remodels features\n",
    "    # features = [['LotArea', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'TotalFinSF', 'TotalBath', 'BedroomAbvGr', 'GarageCars', 'YrSold','Foundation']]\n",
    "    x = np.array([[23958, 8, 1962, 2011, 2822, 2.5, 5, 2, 2011, 0, 0,1,0,0]])\n",
    "    #x = np.array(data_in),reshape(1,-1)    # load model\n",
    "    model = load_models()\n",
    "    prediction = model.predict(x)[0]    \n",
    "    response = json.dumps({'response': prediction})\n",
    "    return response, 200\n",
    "\n",
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c97b2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
